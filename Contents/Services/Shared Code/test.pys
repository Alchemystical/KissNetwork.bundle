#!/usr/bin/env python

"""KissNetwork shared code"""

# import section(s) not included in Plex Plug-In Framwork
import sys, os, io, json
import domain as Domain

# constants
BUNDLE_PATH = os.path.join(os.getcwd().lstrip('\?').rsplit('Plug-in Support')[0], 'Plug-ins', 'KissNetwork.bundle')
RESOURCES_PATH = os.path.join(BUNDLE_PATH, 'Contents', 'Resources')
MODULE_PATH = os.path.join(BUNDLE_PATH, 'Contents', 'Modules')
SUPPORT_PATH = os.path.join(BUNDLE_PATH.split('Plug-ins')[0], 'Plug-in Support', 'Data', 'com.plexapp.plugins.kissnetwork')
HEADER_FILE = os.path.join(SUPPORT_PATH, 'Header_Dict')

# set constants from shared domain.pys
USER_AGENT = Domain.USER_AGENT
Domain_Dict = Domain.LoadDomainDict()

ANIME_BASE_URL = Domain_Dict['Anime']
ASIAN_BASE_URL = Domain_Dict['Asian']
CARTOON_BASE_URL = Domain_Dict['Cartoon']
MANGA_BASE_URL = Domain_Dict['Manga']

BASE_URL_LIST = [
    ('Anime', ANIME_BASE_URL), ('Drama', ASIAN_BASE_URL),
    ('Cartoon', CARTOON_BASE_URL), ('Manga', MANGA_BASE_URL)
    ]

# add custom modules to python path
if MODULE_PATH not in sys.path:
    sys.path.append(MODULE_PATH)
    Log.Debug('\n----------\n%s\n---^^^^---added to sys.path---^^^^---\n----------By test.pys----------' % MODULE_PATH)

# Import cfscrape from MODULE_PATH
import cfscrape

####################################################################################################
def CFTest():
    """ test cfscrape, if error then need javascript runtime """

    cookie = cfscrape.get_cookie_string(url=ANIME_BASE_URL, user_agent=USER_AGENT)

    return str(cookie)

####################################################################################################
def GetTypeTitle(url):
    """ Get type title from URL """

    type_title = url.rsplit('/')[2].rsplit('kiss')[1].rsplit('.')[0].title()
    # correct type_title
    if type_title == 'Asian':
        type_title = 'Drama'

    return type_title

####################################################################################################
def CreateHeadersDict():
    """Genreate Header Dict Data, then send to SaveHeaderDict()"""

    Log.Debug('Headers dictionary not yet created. Creating new Header Dict and filling in data')

    # Get cookies for URLs and save to Header Dict for future use.
    for i, (type_title, base_url) in enumerate(BASE_URL_LIST):
        cookie, user_agent = cfscrape.get_cookie_string(url=base_url, user_agent=USER_AGENT)
        if i == 0:
            temp_dict = {
                type_title: {
                    'cookie': cookie, 'user-agent': user_agent,
                    'date': str(Datetime.Now()), 'referer': base_url
                    }
                }
        else:
            temp_dict.update({
                type_title: {
                    'cookie': cookie, 'user-agent': user_agent,
                    'date': str(Datetime.Now()), 'referer': base_url
                    }
                })

        Log.Debug('cookies for %s = %s' %(type_title, temp_dict[type_title]['cookie']))
        Log.Debug('current header dict = %s' %temp_dict)

    SaveHeaderDict(temp_dict)

    return temp_dict

####################################################################################################
def GetHeadersForURL(url):
    """
    Set headers for URL. Return headers from headers dict.
    If cookies have expired then get new ones.
    """

    Log.Debug('url to get headers = %s' %url)

    # get base url for headers
    base_url = GetBaseURL(url)

    # get title for headers
    type_title = GetTypeTitle(url)

    # get current datetime
    current_datetime = Datetime.Now()

    # cookie time constants for each site.
    time_constants = {
        'Anime': Datetime.Delta(days=1), 'Cartoon': Datetime.Delta(days=7),
        'Drama': Datetime.Delta(minutes=30), 'Manga': Datetime.Delta(days=6)}

    test = None
    header_data = LoadHeaderDict()

    if len(header_data) > 1:
        # Update Header Dictionary
        cachetime = Datetime.ParseDate(header_data[type_title]['date'])
        deltatime = current_datetime - cachetime

        if deltatime >= time_constants[type_title]:
            Log.Info('\n----------Time to update %s cookies----------' %type_title)

            cookie, user_agent = cfscrape.get_cookie_string(url=base_url, user_agent=USER_AGENT)
            header_data.update({
                type_title: {
                    'cookie': cookie, 'user-agent': user_agent,
                    'referer': base_url, 'date': str(Datetime.Now())}})

            Log.Info('\n----------Updated %s Header to----------\n%s\n----------' %(type_title, header_data[type_title]))

            # update header dict
            SaveHeaderDict(header_data)
            Log.Info('\n----------New Cookies saved for %s Header----------' %base_url)
        else:
            Log.Debug('Time left until %s cookies need to be updated = %s' %(type_title, str(time_constants[type_title] - deltatime)))
    else:
        CreateHeadersDict()
        header_data = LoadHeaderDict()

    # setup headers to return, do not want date in header field
    headers_to_return = {
        'cookie': header_data[type_title]['cookie'],
        'user-agent': header_data[type_title]['user-agent'],
        'referer': header_data[type_title]['referer']
        }

    Log.Debug('\n----------Header for %s Loaded----------' %base_url)

    return headers_to_return

####################################################################################################
def SaveHeaderDict(content=dict):
    """ Save Header Dict to file """

    Log.Debug('Saving Header to file')

    with io.open(HEADER_FILE, 'wb') as f:
        json.dump(content, f, indent=4, sort_keys=True, separators=(',', ': '))

    Log.Debug('Header Dictionary file has been saved')

    return content

####################################################################################################
def LoadHeaderDict():
    """Load Header Dict"""

    Log.Debug('header dict file location = %s' %HEADER_FILE)

    if os.path.isfile(HEADER_FILE):
        Log.Info('loading header dict in json format')
        with io.open(HEADER_FILE) as data_file:
            data = json.load(data_file)

        return data
    else:
        Log.Debug('header dict file not found')
        Log.Debug('creating new header dict file')

        return CreateHeaderDict()

####################################################################################################
def GetBaseURL(url):
    """ Get base url for headers """

    base_url = 'http://' + url.split('/')[2]
    type_title = GetTypeTitle(base_url)
    if not (type_title, base_url) in BASE_URL_LIST:
        for node in BASE_URL_LIST:
            if node[0] == type_title:
                base_url = node[1]
                break

    return base_url

####################################################################################################
def CoverImageFileExist(image_file):
    """Check if resource file exist"""

    if os.path.isfile(os.path.join(RESOURCES_PATH, image_file)):
        return True
    else:
        return False
