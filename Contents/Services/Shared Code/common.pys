#!/usr/bin/env python

"""
KissNetwork shared code.
Shared common code.
"""

# import section(s) not included in Plex Plug-In Framwork
import os
import pickle
import shutil
from io import open
import domain as Domain

# path constants
BUNDLE_PATH = Domain.BUNDLE_PATH
RESOURCES_PATH = os.path.join(BUNDLE_PATH, 'Contents', 'Resources')
SUPPORT_PATH = Domain.SUPPORT_PATH

# general constants
PREFIX = '/video/kissnetwork'
TITLE = 'KissNetwork'
TIMEOUT = Datetime.Delta(hours=1)
USER_AGENT = Domain.USER_AGENT
LIST_VIEW_CLIENTS = ['Android', 'iOS']

####################################################################################################
def ParseVersion(version):
    try:
        return tuple(map(int, (version.split('.'))))
    except:
        return version

####################################################################################################
def TypeTitleList():
    return ['Anime', 'Drama', 'Cartoon', 'Manga', 'Comic']

####################################################################################################
def BaseURL(kind):
    return [u for t, u in BaseURLListTuple() if t == kind][0]

####################################################################################################
def SearchURL(kind):
    return BaseURL(kind) + '/Search/{}'.format(kind) + '?keyword={}'

####################################################################################################
def SearchURLList():
    search_url_list = []
    for t in TypeTitleList():
        search_url_list.append(SearchURL(t))
    return search_url_list

####################################################################################################
def BaseURLList():
    base_url_list = []
    for u in URLList():
        base_url_list.append(u)
    return base_url_list

####################################################################################################
def URLList():
    url_list = []
    for t in TypeTitleList():
        url_list.append(DomainDict(t))
    return url_list

####################################################################################################
def BaseURLListTuple():
    base_url_list_t = []
    for u in URLList():
        base_url_list_t.append((GetTypeTitle(u), u))
    return base_url_list_t

####################################################################################################
def DomainDict(kind):
    d = Domain.LoadDomainDict()
    if len(d.keys()) != 5 or 'Asian' in d.keys():
        Domain.CreateDomainDict()
        d = Domain.LoadDomainDict()
    return d[kind]

####################################################################################################
def CorrectURL(url):
    return GetBaseURL(url) + '/' + url.split('/', 3)[3] if (len(url.split('/')) > 3) else GetBaseURL(url)

####################################################################################################
def GetTypeTitle(url):
    """ Get type title from URL """

    r = Regex(r'^https?\:\/\/(?:www\.)?(?:kiss|read)(comic|\w+)(?:online)?\.\w+').search(url)
    type_title = r.group(1).title() if r else None

    return 'Drama' if type_title == 'Asian' else type_title

####################################################################################################
def GetBaseURL(url):
    """ Get base url for headers """

    type_title = GetTypeTitle(url)
    base_url = Regex(r'(https?\:\/\/(?:www\.)?\w+\.\w+)').search(url).group(1)
    if not (type_title, base_url) in BaseURLListTuple():
        for node in BaseURLListTuple():
            if node[0] == type_title:
                base_url = node[1]
                break

        Log.Warn('* Old {} URL parsed from page! URL Domain changed to {}'.format(type_title, base_url))
        Log.Warn('* {}'.format(url))

    return base_url

####################################################################################################
def ensure_dirs(path):
    if not os.path.exists(path):
        try:
            os.makedirs(path)
        except:
            raise

####################################################################################################
def file_exists(path):
    return os.path.exists(path) and os.path.isfile(path)

####################################################################################################
def data_item_path(itemname):
    return os.path.join(SUPPORT_PATH, 'DataItems', itemname)

####################################################################################################
def dataHTTP(itemname):
    return os.path.join('DataHTTP', itemname)

####################################################################################################
def dataCovers(itemname):
    return os.path.join('DataCovers', itemname)

####################################################################################################
def DataExists(itemname):
    return os.path.isfile(data_item_path(itemname)) and (os.stat(data_item_path(itemname)).st_size != 0)

####################################################################################################
def DataCoverExists(image_file):
    if image_file:
        if DataExists(dataCovers(image_file)):
            return True
    Log.Warn('* {} does not exist.'.format(image_file))
    return False

####################################################################################################
def DataLoad(itemname, is_object=False):
    if DataExists(itemname):
        filename = os.path.abspath(data_item_path(itemname))
        try:
            with open(filename, 'rb') as f:
                data = f.read()
            if is_object:
                return pickle.loads(data)
            else:
                return data
        except Exception, e:
            Log.Critical(u'* {}'.format(e))
    return None

####################################################################################################
def DataSave(itemname, data, is_object=False):
    if data == None:
        Log.Error('* No data to Save for \'{}\''.format(itemname))
        return

    if is_object:
        data = pickle.dumps(data)

    filename = os.path.abspath(data_item_path(itemname))
    tempfile = '{}/._{}'.format(os.path.dirname(filename), os.path.basename(filename))
    try:
        if os.path.exists(tempfile):
            os.remove(tempfile)
        with open(tempfile, 'wb') as f:
            f.write(str(data))
        if os.path.exists(filename):
            os.remove(filename)
        shutil.move(tempfile, filename)
    except Exception, e:
        Log.Error(u'* {}'.format(e))
        if os.path.exists(tempfile):
            os.remove(tempfile)
        raise

####################################################################################################
def data_object(filepath):
    img_data = DataLoad(filepath)
    if not img_data:
        Log.Error('* Cannot find {}'.format(filepath))
        return None

    ext = String.SplitExtension(filepath)[-1]
    mime_type = {
        '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png',
        '.gif': 'image/gif',  '.tiff': 'image/tiff', '.bmp': 'image/bmp'
        }.get(ext, '*/*')

    return DataObject(img_data, mime_type)

####################################################################################################
def load_data_cover_file(filename):
    filepath = data_cover_file(filename)
    return '/photo/:/transcode?url={}&width={}&height={}&maxSize=1'.format(String.Quote(filepath), 200, 260)

####################################################################################################
def is_kiss_url(url):
    return bool(Regex(r'^https?\:\/\/(?:www\.)?(readcomiconline|kiss\w+)\.\w+\/.+$').search(url))

####################################################################################################
def CorrectCoverImage(string):
    """Correct Cover Image file name"""

    if string:
        if is_kiss_url(string):
            string = GetBaseURL(string) + '/' + string.split('/', 3)[3]
        elif 'cdn.myanimelist.net' in string:
            string = 'http://' + string.split('/', 2)[2]

        name, ext = String.SplitExtension(string)
        ext_l = ext.lower()

        if (ext_l == '.jpg') or (ext_l == '.jpeg') or (ext_l == '.png') or (ext_l == '.gif'):
            string = name + ext_l
        else:
            if ext_l == '.jp' or ext_l == '.pn':
                string = name + ext_l + 'g'
            elif ext_l == '.j':
                string = name + ext_l + 'pg'
            elif ext_l == '.p':
                string = name + ext_l + 'ng'
            elif ext_l == '.gi':
                string = name + ext_l + 'f'
            elif ext_l == '.g':
                string = name + ext_l + 'if'
            else:
                Log.Error('Content_url not valid picture | {}'.format(string))
                string = None
    else:
        pass

    return string

####################################################################################################
def StringCode(string, code):
    """Handle String Coding"""

    if string:
        if code == 'encode':
            string_code = String.Quote(string.encode('utf-8'))
        elif code == 'decode':
            # Â artifact in Windows OS, don't know why, think it has to do with the Dict protocall
            string_code = String.Unquote(string).decode('utf-8').replace('Â', '')
    else:
        string_code = None

    return string_code
